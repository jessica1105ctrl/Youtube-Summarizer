{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNyQWhvL68SwetS4Bi03XHd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jessica1105ctrl/Youtube-Summarizer/blob/main/YoutubeSummarizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75HuAI-otXfv",
        "outputId": "6eaed2f9-6366-4efc-d448-fa3a47efe33d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paste a YouTube link: https://www.youtube.com/watch?v=6uUblznfrsk\n",
            "\n",
            "ğŸ“Â Summary:\n",
            "\n",
            "Mahendra and Mahendra was founded by Two Brothers around the time of Independence. Winston Churchill did not expect India to survive or to mold itself into a viable country. Three decades later here we are a multi-billion dollar group still chugging along.\n"
          ]
        }
      ],
      "source": [
        "# ================== ğŸ“¦ 1. Install once per runtime ==================\n",
        "!pip install --quiet youtube-transcript-api transformers\n",
        "\n",
        "# ================== ğŸ§‘â€ğŸ’» 2. Imports & model load ==================\n",
        "import re\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\n",
        "    \"summarization\",\n",
        "    model=\"facebook/bart-large-cnn\",   # swap for a lighter model if needed\n",
        "    device_map=\"auto\"                  # GPU in Colab, CPU elsewhere\n",
        ")\n",
        "\n",
        "# ================== ğŸ” 3. Helper functions ==================\n",
        "def extract_video_id(url:str) -> str|None:\n",
        "    \"\"\"\n",
        "    Works for long and short YouTube URLs.\n",
        "    \"\"\"\n",
        "    match = re.search(r\"(?:v=|youtu\\.be/)([\\w\\-]{11})\", url)\n",
        "    return match.group(1) if match else None\n",
        "\n",
        "\n",
        "def fetch_transcript_text(video_id:str, lang_priority:list[str]=[\"en\", \"en-US\"]) -> str:\n",
        "    \"\"\"\n",
        "    Uses the new v1.x API:\n",
        "       ytt_api = YouTubeTranscriptApi()\n",
        "       ytt_api.fetch(video_id).to_raw_data()\n",
        "    \"\"\"\n",
        "    ytt_api = YouTubeTranscriptApi()\n",
        "    try:\n",
        "        # pick the first matching language transcript\n",
        "        transcript_obj = ytt_api.list(video_id).find_transcript(lang_priority)\n",
        "        raw_segments   = transcript_obj.fetch().to_raw_data()\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Transcript fetch failed: {e}\")\n",
        "\n",
        "    return \" \".join(seg[\"text\"] for seg in raw_segments)\n",
        "\n",
        "\n",
        "def summarize_long_text(text:str,\n",
        "                        chunk_chars:int=4000,\n",
        "                        max_len:int=150,\n",
        "                        min_len:int=30) -> str:\n",
        "    \"\"\"\n",
        "    Splits very long transcripts into manageable chunks, summarises each,\n",
        "    then summarises the summaries.\n",
        "    \"\"\"\n",
        "    summaries = []\n",
        "    for start in range(0, len(text), chunk_chars):\n",
        "        chunk = text[start : start + chunk_chars]\n",
        "        summary = summarizer(\n",
        "            chunk,\n",
        "            max_length=max_len,\n",
        "            min_length=min_len,\n",
        "            do_sample=False\n",
        "        )[0][\"summary_text\"]\n",
        "        summaries.append(summary)\n",
        "\n",
        "    # If we produced multiple partial summaries, compress them once more\n",
        "    return (summaries[0] if len(summaries) == 1\n",
        "            else summarizer(\" \".join(summaries),\n",
        "                            max_length=max_len,\n",
        "                            min_length=min_len,\n",
        "                            do_sample=False)[0][\"summary_text\"])\n",
        "\n",
        "\n",
        "def summarize_youtube(url:str) -> str:\n",
        "    video_id = extract_video_id(url)\n",
        "    if not video_id:\n",
        "        return \"âŒÂ Could not extract a valid YouTube video ID from that link.\"\n",
        "\n",
        "    try:\n",
        "        transcript_text = fetch_transcript_text(video_id)\n",
        "    except RuntimeError as err:\n",
        "        return f\"âŒÂ {err}\"\n",
        "\n",
        "    return summarize_long_text(transcript_text)\n",
        "\n",
        "# ================== ğŸš€ 4. Example usage ==================\n",
        "if __name__ == \"__main__\":\n",
        "    link = input(\"Paste a YouTube link: \").strip()\n",
        "    print(\"\\nğŸ“Â Summary:\\n\")\n",
        "    print(summarize_youtube(link))\n",
        "v"
      ]
    }
  ]
}